{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessory Packages\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset in pandas data frames\n",
    "df = pd.DataFrame() \n",
    "test_data=pd.read_csv('http://kevincrook.com/utd/market_basket_test.txt', names=list('abcd'))\n",
    "train_data=pd.read_csv('http://kevincrook.com/utd/market_basket_training.txt',names=list('abcde'))\n",
    "train_data= train_data.fillna(0)\n",
    "test_data=test_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing train datasets into buckets of 2, 3 and 4\n",
    "two_set=train_data.query('(b!=0)&(c!=0)&(d==0) & (e==0)')\n",
    "three_set=train_data.query('(b!=0)&(c!=0)&(d!=0) & (e==0)')\n",
    "four_set=train_data.query('(b!=0)&(c!=0)&(d!=0) & (e!=0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting frequency of each bucket in train data set\n",
    "df_two=two_set.groupby(['b','c']).count().reset_index()\n",
    "df_two=df_two[['b','c','a']]\n",
    "df_two = df_two.sort_values([\"b\",\"a\"], ascending=False) \n",
    "df_two = df_two.sort_values([\"b\"], ascending=True)\n",
    "df_three=three_set.groupby(['b','c','d']).count().reset_index()\n",
    "df_three=df_three[['b','c','d','a']]\n",
    "df_four=four_set.groupby(['b','c','d','e']).count().reset_index()\n",
    "df_four=df_four[['b','c','d','e','a']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting buckets into sets\n",
    "df_two['d']=df_two[['b','c']].values.tolist()\n",
    "df_two['d']=df_two.apply(lambda row: set(row['d']) if row['d'] else 1, axis=1)\n",
    "df_two['e']=df_two[['b']].values.tolist()\n",
    "df_two['e']=df_two.apply(lambda row: set(row['e']) if row['e'] else 1, axis=1)\n",
    "df_two['f']=df_two[['c']].values.tolist()\n",
    "df_two['f']=df_two.apply(lambda row: set(row['f']) if row['f'] else 1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_three['e']=df_three[['b','c','d']].values.tolist()\n",
    "df_three['e']=df_three.apply(lambda row: set(row['e']) if row['e'] else 1, axis=1)\n",
    "df_three['f']=df_three[['b']].values.tolist()\n",
    "df_three['f']=df_three.apply(lambda row: set(row['f']) if row['f'] else 1, axis=1)\n",
    "df_three['g']=df_three[['c']].values.tolist()\n",
    "df_three['g']=df_three.apply(lambda row: set(row['g']) if row['g'] else 1, axis=1)\n",
    "df_three['h']=df_three[['d']].values.tolist()\n",
    "df_three['h']=df_three.apply(lambda row: set(row['h']) if row['h'] else 1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_four['f']=df_four[['b','c','d','e']].values.tolist()\n",
    "df_four['f']=df_four.apply(lambda row: set(row['f']) if row['f'] else 1, axis=1)\n",
    "df_four['g']=df_four[['b']].values.tolist()\n",
    "df_four['g']=df_four.apply(lambda row: set(row['g']) if row['g'] else 1, axis=1)\n",
    "df_four['h']=df_four[['c']].values.tolist()\n",
    "df_four['h']=df_four.apply(lambda row: set(row['h']) if row['h'] else 1, axis=1)\n",
    "df_four['i']=df_four[['d']].values.tolist()\n",
    "df_four['i']=df_four.apply(lambda row: set(row['i']) if row['i'] else 1, axis=1)\n",
    "df_four['j']=df_four[['e']].values.tolist()\n",
    "df_four['j']=df_four.apply(lambda row: set(row['j']) if row['j'] else 1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing test dataset into bucket of one, two and three\n",
    "one_set_test=test_data.query('(b!=0)&(c==0)&(d==0)')\n",
    "two_set_test=test_data.query('(b!=0)&(c!=0)&(d==0)')\n",
    "three_set_test=test_data.query('(b!=0)&(c!=0)&(d!=0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gettin count of each bucket in test\n",
    "df_one_test=one_set_test.groupby(['b']).count().reset_index()\n",
    "df_one_test=df_one_test[['b','a']]\n",
    "df_two_test=two_set_test.groupby(['b','c']).count().reset_index()\n",
    "df_two_test=df_two_test[['b','c','a']]\n",
    "df_three_test =three_set_test.groupby(['b','c','d']).count().reset_index()\n",
    "df_three_test=df_three_test[['b','c','d','a']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion in to sets\n",
    "df_one_test['c']=df_one_test[['b']].values.tolist()\n",
    "df_one_test['c']=df_one_test.apply(lambda row: set(row['c']) if row['c'] else 1, axis=1)\n",
    "df_two_test['d']=df_two_test[['b','c']].values.tolist()\n",
    "df_two_test['d']=df_two_test.apply(lambda row: set(row['d']) if row['d'] else 1, axis=1)\n",
    "df_three_test['e']=df_three_test[['b','c','d']].values.tolist()\n",
    "df_three_test['e']=df_three_test.apply(lambda row: set(row['e']) if row['e'] else 1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populating list for bucket of one\n",
    "last = []\n",
    "a = 0\n",
    "for index, row in df_one_test.iterrows():\n",
    "    for index, rows in df_two.iterrows():\n",
    "        if row['b'] == rows['b'] or row['b'] == rows['c']:\n",
    "            last.append(a)        #sort key\n",
    "            last.append(row['c']) #original set\n",
    "            last.append(row['c']) #resulting set\n",
    "            last.append('null')         #removed item\n",
    "            last.append(rows['d'])#matched set\n",
    "            last.append(rows['d']-row['c']) #recommended\n",
    "            last.append(rows['a'])#count\n",
    "    a=a+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populating list for bucket of two\n",
    "b = 8\n",
    "for index, row3 in df_two_test.iterrows():\n",
    "    x = (row3['d'] - {'P04','P08'})\n",
    "    if len(x) == 1:\n",
    "        for index, rows1 in df_two.iterrows():\n",
    "            if x == rows1['e'] or x == rows1['f']:\n",
    "                last.append(b)         #sort key\n",
    "                last.append(row3['d']) #original set\n",
    "                last.append(x)         #resulting set\n",
    "                last.append(row3['d']-x) #removed item\n",
    "                last.append(rows1['d']) #matched set\n",
    "                last.append(rows1['d']-x)\n",
    "                last.append(rows1['a']) #count\n",
    "    else:\n",
    "        for index, rows2 in df_three.iterrows():\n",
    "            if row3['b'] == rows2['b'] or row3['b'] == rows2['c'] or row3['b'] == rows2['d']:\n",
    "                if row3['c'] == rows2['b'] or row3['c'] == rows2['c'] or row3['c'] == rows2['d']:\n",
    "                    last.append(b)\n",
    "                    last.append(row3['d'])\n",
    "                    last.append(x) \n",
    "                    last.append(row3['d']-x)\n",
    "                    last.append(rows2['e'])\n",
    "                    last.append(rows2['e']-x)\n",
    "                    last.append(rows2['a'])\n",
    "    b=b+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Populating list for bucket of three\n",
    "c = 45\n",
    "for index, row1 in df_three_test.iterrows():\n",
    "    x = (row1['e'] - {'P04','P08'})\n",
    "    if len(x) == 1:\n",
    "        for index, rows2 in df_two.iterrows():\n",
    "            if x.issubset(rows2['d']):\n",
    "                last.append(c)\n",
    "                last.append(row1['e'])\n",
    "                last.append(x)\n",
    "                last.append(row1['e']-x)\n",
    "                last.append(rows2['d'])\n",
    "                last.append(rows2['d']-x)\n",
    "                last.append(rows2['a'])\n",
    "    elif len(x) == 2:\n",
    "        for index, rows3 in df_three.iterrows():\n",
    "            if x.issubset(rows3['e']):\n",
    "                last.append(c)\n",
    "                last.append(row1['e'])\n",
    "                last.append(x)\n",
    "                last.append(row1['e']-x)\n",
    "                last.append(rows3['e'])\n",
    "                last.append(rows3['e']-x)\n",
    "                last.append(rows3['a'])\n",
    "    else:\n",
    "        for index, rows4 in df_four.iterrows():\n",
    "            if x.issubset(rows4['f']):\n",
    "                    last.append(c)\n",
    "                    last.append(row1['e'])\n",
    "                    last.append(x)\n",
    "                    last.append(row1['e']-x)\n",
    "                    last.append(rows4['f'])\n",
    "                    last.append(rows4['f']-x)\n",
    "                    last.append(rows4['a'])\n",
    "    c = c+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting list into dataframe \n",
    "final = pd.DataFrame(np.array(last).reshape(599,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns\n",
    "final.columns = ['sortk','original_set','removed_set','removed', 'matched','result','count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting the buckets descending\n",
    "final = final.assign(sortkey = final.removed.apply(list).str[0])\\\n",
    "     .sort_values(by=['sortk','count'], ascending=[True, False])\\\n",
    "     .drop('sortkey', axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reseting index\n",
    "final=final.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing duplicates for uniquie buckets keeping only max\n",
    "g = final.sort_values('count', ascending=False).drop_duplicates(['sortk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset index\n",
    "g = g.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping required columns only\n",
    "df1 = g[['sortk','original_set','removed_set','removed','matched','result','count']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populating recommened list bucket\n",
    "list1=[]\n",
    "for index1, r in final.iterrows():\n",
    "    list1.append(r['original_set'])\n",
    "    list1.append(r['removed_set'])\n",
    "    list1.append(r['removed'])\n",
    "    list1.append(r['matched'])\n",
    "    list1.append(r['result'])\n",
    "    list1.append(r['count'])\n",
    "    for index2, r1 in df1.iterrows():\n",
    "        if r['sortk'] == r1['sortk']:\n",
    "            list1.append(r1['result'])\n",
    "            list1.append(r1['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting list into data frame\n",
    "f = pd.DataFrame(np.array(list1).reshape(599,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming final dataframe\n",
    "f.columns = ['Original Set','Filtered Set','Removed Item','Matched Set', 'Extra Item','Item Count','Recommended Item','Max Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting in csv \n",
    "f.to_csv(\"Recommended.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
